% 25.07.2017 23:43 bh

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
						PAML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{wainwright2012paml,
	title={Privacy aware learning},
	author={Wainwright, Martin J and Jordan, Michael I and Duchi, John C},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1430--1438},
	year={2012}
}

@inproceedings{malle2016right,
	title={The right to be forgotten: towards machine learning on perturbed knowledge bases},
	author={Malle, Bernd and Kieseberg, Peter and Weippl, Edgar and Holzinger, Andreas},
	booktitle={International Conference on Availability, Reliability, and Security},
	pages={251--266},
	year={2016},
	organization={Springer}
}

@incollection{MalleKieseHolzinger:2017:DoNotDisturb,
	year = {2017},
	author = {Malle, Bernd and Kieseberg, Peter and Holzinger, Andreas},
	title = {DO NOT DISTURB? Classifier behavior on perturbed datasets.},
	booktitle = {Machine Learning and Knowledge Extraction, IFIP CD-MAKE, Lecture Notes in Computer Science LNCS Volume 10410},
	publisher = {Springer},
	address = {Cham},
	pages = {155-173}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		interactive Machine Learning
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@incollection{iMLExperiment,
	year = {2016},
	author = {Holzinger, A and Plass, M and Holzinger, K and Crisan, GC and Pintea, CM and Palade, V },
	title = {Towards interactive Machine Learning (iML): Applying Ant Colony Algorithms to solve the Traveling Salesman Problem with the Human-in-the-Loop approach},
	booktitle = { IFIP International Cross Domain Conference and Workshop (CD-ARES)},
	publisher = {Springer},
	address = {Heidelberg, Berlin, New York},
	pages = {81-95},
	abstract = {Most Machine Learning (ML) researchers focus on automatic Machine Learning (aML) where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from the availability of "big data". However, sometimes, for example in health informatics, we are confronted not a small number of data sets or rare events, and with complex problems where aML-approaches fail or deliver unsatisfactory results. Here, interactive Machine Learning (iML) may be of help and the "human-in-the-loop" approach may be beneficial in solving computationally hard problems, where human expertise can help to reduce an exponential search space through heuristics. <br/>In this paper, experiments are discussed which help to evaluate the effectiveness of the iML-"human-in-the-loop" approach, particularly in opening the "black box", thereby enabling a human to directly and indirectly manipulating and interacting with an algorithm. For this purpose, we selected the Ant Colony Optimization (ACO) framework, and use it on the Traveling Salesman Problem (TSP) which is of high importance in solving many practical problems in health informatics, e.g. in the study of proteins.}
}

@article{Holzinger:2016:iML,
	year = {2016},
	author = {Holzinger, Andreas},
	title = {Interactive Machine Learning for Health Informatics: When do we need the human-in-the-loop?},
	journal = {Springer Brain Informatics (BRIN)},
	volume = {3},
	number = {2},
	pages = {119-131},
	abstract = {Machine learning (ML) is the fastest growing field in computer science, and health informatics is amongst the greatest challenges. The goal of ML is to develop algorithms which can learn and improve over time and can be used for predictions. Most ML researchers concentrate on automatic Machine Learning (aML), where great advances have been made, for example, in speech recognition, recommender systems, or autonomous vehicles. Automatic approaches greatly benefit from big data with many training sets. However, in the health domain, sometimes we are confronted with a small number of data sets or rare events, where aML-approaches suffer of insufficient training samples. Here interactive Machine Learning (iML) may be of help, having its roots in Reinforcement Learning (RL), Preference Learning (PL) and Active Learning (AL). The term iML is not yet well used, so we define it as algorithms that can interact with agents and can optimize their learning behaviour through these interactions, where the agents can also be human. This human-in-the-loop can be beneficial in solving computationally hard problems, e.g., subspace clustering, protein folding, or k-anonymization of health data, where human expertise can help to reduce an exponential search space through heuristic selection of samples. Therefore, what would otherwise be an NP-hard problem, reduces greatly in complexity through the input and the assistance of a human agent involved in the learning phase.},
	keywords = {interactive Machine learning, health informatics},
	doi = {10.1007/s40708-016-0042-6},
	url = {http://dx.doi.org/10.1007/s40708-016-0042-6}
}

@article{Kieseberg:2016:Doctor-in-the-Loop,
	year = {2016},
	author = {Kieseberg, Peter and Malle, Bernd and Frühwirt, Peter and Weippl, Edgar and Holzinger, Andreas},
	title = {A tamper-proof audit and control system for the doctor in the loop},
	journal = {Brain Informatics},
	pages = {1-11},
	abstract = {The “doctor in the loop” is a new paradigm in information-driven medicine, picturing the doctor as authority inside a loop supplying an expert system with information on actual patients, treatment results, and possible additional (side-)effects, including general information in order to enhance data-driven medical science, as well as giving back treatment advice to the doctor himself. While this approach can be very beneficial for new medical approaches like P4 medicine (personal, predictive, preventive, and participatory), it also relies heavily on the authenticity of the data and thus increases the need for secure and reliable databases. In this paper, we propose a solution in order to protect the doctor in the loop against responsibility derived from manipulated data, thus enabling this new paradigm to gain acceptance in the medical community. This work is an extension of the conference paper Kieseberg et al. (Brain Informatics and Health, 2015), which includes extensions to the original concept.},
	doi = {10.1007/s40708-016-0046-2},
	url = {http://dx.doi.org/10.1007/s40708-016-0046-2}
}

@article{Xiao2009,
	abstract = {There has been much recent work on algorithms for limiting disclosure in data publishing, however they have not been put to use in any toolkit for practicioners. We will demonstrate CAT, the Cornell Anonymization Toolkit, designed for interactive anonymization. CAT has an interface that is easy to use; it guides users through the process of preparing a dataset for publication while limiting disclosure through the identification of records that have high risk under various attacker models.},
	author = {Xiao, Xiaokui and Wang, Guozhang and Gehrke, Johannes},
	doi = {10.1145/1559845.1559979},
	file = {:home/bernd/Dropbox/hotstuff/iML/Interactive Anonymization of Sensitive Data.pdf:pdf},
	isbn = {9781605585512},
	journal = {Proceedings of the 35th SIGMOD international conference on Management of data - SIGMOD '09},
	keywords = {data anonymization,l -diversity},
	pages = {1051},
	title = {{Interactive anonymization of sensitive data}},
	url = {http://dl.acm.org/citation.cfm?id=1559845.1559979},
	year = {2009}
}

@article{Amershi2012,
	abstract = {We present ReGroup, a novel end-user interactive machine learning system for helping people create custom, on demand groups in online social networks. As a person adds members to a group, ReGroup iteratively learns a probabilistic model of group membership specific to that group. ReGroup then uses its currently learned model to suggest additional members and group characteristics for filtering. Our evaluation shows that ReGroup is effective for helping people create large and varied groups, whereas traditional methods (searching by name or selecting from an alphabetical list) are better suited for small groups whose members can be easily recalled by name. By facilitating on demand group creation, ReGroup can enable in-context sharing and potentially encourage better online privacy practices. In addition, applying interactive machine learning to social network group creation introduces several challenges for designing effective end-user interaction with machine learning. We identify these challenges and discuss how we address them in ReGroup.},
	author = {Amershi, Saleema and Fogarty, James and Weld, Daniel},
	doi = {10.1145/2207676.2207680},
	file = {:home/bernd/Dropbox/hotstuff/iML/ReGroup$\backslash$: Interactive Machine Learning for On-Demand Group Creation in Social Networks.pdf:pdf},
	isbn = {9781450310154},
	journal = {Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems - CHI '12},
	pages = {21},
	title = {{ReGroup: interactive machine learning for on-demand group creation in social networks}},
	url = {http://www.cs.washington.edu/homes/samershi/papers/amershiCHI2012{\_}ReGroup.pdf{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2207676.2207680},
	year = {2012}
}

@article{Fiebrink2009,
	abstract = {Supervised learning methods have long been used to allow musical interface designers to generate new mappings by example. We propose a method for harnessing machine learning algorithms within a radically interactive paradigm, in which the designer may repeatedly generate examples, train a learner, evaluate outcomes, and modify parameters in real-time within a single software environment. We describe our meta-instrument, the Wekinator, which allows a user to engage in on-the-fly learning using arbitrary control modalities and sound synthesis environments. We provide details regarding the system implementation and discuss our experiences using the Wekinator for experimentation and performance.},
	author = {Fiebrink, R. and Trueman, D. and Cook, P.R.},
	file = {:home/bernd/Dropbox/hotstuff/iML/A Meta-Instrument for Interactive, On-the-fly Machine Learning.pdf:pdf},
	journal = {Proc. NIME},
	keywords = {and he does it,any code,audience,in front of an,joe does all of,live,machine learning,mapping,minutes,on stage during a,performance,this in a few,tools,without writing},
	pages = {3},
	title = {{A metainstrument for interactive, on-the-fly machine learning}},
	url = {http://www.cs.dartmouth.edu/{~}cs104/BodyPartRecognition.pdf{\%}5Cnhttp://www.cs.princeton.edu/{~}fiebrink/publications/FiebrinkTruemanCook{\_}NIME2009.pdf},
	volume = {2},
	year = {2009}
}

@article{Moque2012,
	abstract = {One of the most important inputs for medical research is the information registered in electronic medical records. This information typically contains sensitive data that must be preserved in order to be used for research or educational purposes, depending on the regulations of each country and institution. In order to assure confidentiality of data, different techniques can be used to remove basic identifiers (e.g. names, ids); however, these techniques can be easily bypassed by attackers who know the information that can act as pseudo–identifiers of patients (e.g. birth dates, gender). Although these pseudo–identifiers can also be removed, the information they contain is valuable for medical research. To face this problem, different methods that allow minimizing the risk of sharing confidential information have been proposed. The interactive use of anonymization algorithms for electronic medical records is the main contribution of this paper, dubbed AnonymousData.co: a proposal for anonymization of electronic health records.},
	author = {Moque, Carlos and Pomares, Alexandra and Gonzalez, Rafael},
	doi = {10.1016/j.protcy.2012.09.082},
	file = {:home/bernd/Dropbox/hotstuff/iML/AnonymousDataco - interactive Anonym of EHRs.pdf:pdf},
	isbn = {9781466636675},
	issn = {22120173},
	journal = {Procedia Technology},
	keywords = {Anonymization,Data Mining,Information Loss,k–anonymity},
	pages = {743--752},
	title = {{AnonymousData.co: A Proposal for Interactive Anonymization of Electronic Medical Records}},
	url = {http://www.sciencedirect.com/science/article/pii/S2212017312005130},
	volume = {5},
	year = {2012}
}

@article{Wallace2012,
	abstract = {Medical researchers looking for evidence pertinent to a specific clinical$\backslash$nquestion must navigate an increasingly voluminous corpus of published$\backslash$nliterature. This data deluge has motivated the development of machine$\backslash$nlearning and data mining technologies to facilitate efficient biomedical$\backslash$nresearch. Despite the obvious labor-saving potential of these technologies$\backslash$nand the concomitant academic interest therein, however, adoption$\backslash$nof machine learning techniques by medical researchers has been relatively$\backslash$nsluggish. One explanation for this is that while many machine learning$\backslash$nmethods have been proposed and retrospectively evaluated, they are$\backslash$nrarely (if ever) actually made accessible to the practitioners whom$\backslash$nthey would benefit. In this work, we describe the ongoing development$\backslash$nof an end-to-end interactive machine learning system at the Tufts$\backslash$nEvidence-based Practice Center. More specifically, we have developed$\backslash$nabstrackr, an online tool for the task of citation screening for$\backslash$nsystematic reviews. This tool provides an interface to our machine$\backslash$nlearning methods. The main aim of this work is to provide a case$\backslash$nstudy in deploying cutting-edge machine learning methods that will$\backslash$nactually be used by experts in a clinical research setting.},
	author = {Wallace, Byron C. and Small, Kevin and Brodley, Carla E. and Lau, Joseph and Trikalinos, Thomas a.},
	doi = {10.1145/2110363.2110464},
	file = {:home/bernd/Dropbox/hotstuff/iML/Deploying an Interactive Machine Learning System in an Evidence-Based Practice Center.pdf:pdf},
	isbn = {9781450307819},
	journal = {Proceedings of the 2nd ACM SIGHIT symposium on International health informatics - IHI '12},
	pages = {819},
	title = {{Deploying an interactive machine learning system in an evidence-based practice center}},
	url = {http://dl.acm.org/citation.cfm?doid=2110363.2110464},
	year = {2012}
}

@article{Dwork2014,
	abstract = {The Algorithmic Foundations of Differential Privacy},
	author = {Dwork, Cynthia and Roth, Aaron},
	doi = {10.1561/0400000042},
	file = {:home/bernd/Dropbox/hotstuff/iML/differential{\_}privacy.pdf:pdf},
	isbn = {9781601988188},
	issn = {15513068},
	journal = {Foundations and Trends in Theoretical Computer Science},
	number = {2013},
	pages = {211--407},
	pmid = {21455981},
	title = {{The Algorithmic Foundations of Differential Privacy}},
	volume = {9},
	year = {2014}
}

@article{WARE2001,
	abstract = {According to standard procedure, building a classifier using machine learning is a fully automated process that follows the preparation of training data by a domain expert. In contrast, interactive machine learning engages users in actually generating the classifier themselves. This offers a natural way of integrating background knowledge into the modelling stage—as long as interactive tools can be designed that support efficient and effective communication. This paper shows that appropriate techniques can empower users to create models that compete with classifiers built by state-of-the-art learning algorithms. It demonstrates that users—even users who are not domain experts—can often construct good classifiers, without any help from a learning algorithm, using a simple two-dimensional visual interface. Experiments on real data demonstrate that, not surprisingly, success hinges on the domain: if a few attributes can support good predictions, users generate accurate classifiers, whereas domains with many high-order attribute interactions favour standard machine learning techniques. We also present an artificial example where domain knowledge allows an “expert user” to create a much more accurate model than automatic learning algorithms. These results indicate that our system has the potential to produce highly accurate classifiers in the hands of a domain expert who has a strong interest in the domain and therefore some insights into how to partition the data. Moreover, small expert-defined models offer the additional advantage that they will generally be more intelligible than those generated by automatic techniques.},
	author = {WARE, MALCOLM and FRANK, EIBE and HOLMES, GEOFFREY and HALL, MARK and WITTEN, IAN H},
	doi = {10.1006/ijhc.2001.0499},
	file = {:home/bernd/Dropbox/hotstuff/iML/iML - letting users build classifiers.pdf:pdf},
	issn = {10715819},
	journal = {International Journal of Human-Computer Studies},
	keywords = {classification,decision trees,interactive learning,visualization.},
	number = {3},
	pages = {281--292},
	title = {{Interactive machine learning: letting users build classifiers}},
	url = {http://www.sciencedirect.com/science/article/pii/S1071581901904999},
	volume = {55},
	year = {2001}
}

@article{Loh2010,
	abstract = {This paper focuses on a domain-driven data mining outsourcing scenario whereby a data owner publishes data to an application service provider who returns mining results. To ensure data privacy against an un-trusted party, anonymization, a widely used technique capable of preserving true attribute values and supporting various data mining algorithms is required. Several issues emerge when anonymization is applied in a real world outsourcing scenario. The majority of methods have focused on the traditional data mining paradigm, therefore they do not implement domain knowledge nor optimize data for domain-driven usage. Furthermore, existing techniques are mostly non-interactive in nature, providing little control to users while assuming their natural capability of producing Domain Generalization Hierarchies (DGH). Moreover, previous utility metrics have not considered attribute correlations during generalization. To successfully obtain optimal data privacy and actionable patterns in a real world setting, these concerns need to be addressed. This paper proposes an anonymization framework for aiding users in a domain-driven data mining outsourcing scenario. The framework involves several components designed to anonymize data while preserving meaningful or actionable patterns that can be discovered after mining. In contrast with existing works for traditional data-mining, this framework integrates domain ontology knowledge during DGH creation to retain value meanings after anonymization. In addition, users can implement constraints based on their mining tasks thereby controlling how data generalization is performed. Finally, attribute correlations are calculated to ensure preservation of important features. Preliminary experiments show that an ontology-based DGH manages to preserve semantic meaning after attribute generalization. Also, using Chi-Square as a correlation measure can possibly improve attribute selection before generalization.},
	author = {Loh, Brian C.S. and Then, Patrick H.H.},
	doi = {10.1109/ISDPE.2010.7},
	file = {:home/bernd/Dropbox/hotstuff/iML/Ontology-Enhanced Interactive Anonymization in Domain-Driven Data Mining Outsourcing.pdf:pdf},
	isbn = {9780769542034},
	journal = {Proceedings - 2nd International Symposium on Data, Privacy, and E-Commerce, ISDPE 2010},
	keywords = {Anonymization,Data publishing,Domain-driven data mining,Outsourcing,Privacy},
	number = {June},
	pages = {9--14},
	title = {{Ontology-enhanced interactive anonymization in domain-driven data mining outsourcing}},
	year = {2010}
}

@article{Amershi2014,
	abstract = {Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.},
	author = {Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
	doi = {10.1609/aimag.v35i4.2513},
	file = {:home/bernd/Dropbox/hotstuff/iML/Power to the People - The Role of Humans in Interactive Machine Learning.pdf:pdf},
	issn = {0738-4602},
	journal = {AI Magazine},
	keywords = {Interactive Machine Learning},
	number = {4},
	pages = {105--120},
	title = {{Power to the People: The Role of Humans in Interactive Machine Learning}},
	url = {http://aaaipress.org/ojs/index.php/aimagazine/article/view/2513},
	volume = {35},
	year = {2014}
}

@article{Chaudhuri2008,
	abstract = {This paper addresses the important tradeoff between privacy and learnability, when designing algorithms for learning from private databases. We focus on privacy-preserving logistic regression. First we apply an idea of Dwork et al. [6] to design a privacy-preserving logistic regression algorithm. This involves bound-ing the sensitivity of regularized logistic regression, and perturbing the learned classifier with noise proportional to the sensitivity. We then provide a privacy-preserving regularized logistic regression algorithm based on a new privacy-preserving technique: solving a perturbed optimization problem. We prove that our algorithm preserves privacy in the model due to [6]. We provide learning guarantees for both algorithms, which are tighter for our new algorithm, in cases in which one would typically apply logistic regression. Ex-periments demonstrate improved learning performance of our method, versus the sensitivity method. Our privacy-preserving technique does not depend on the sen-sitivity of the function, and extends easily to a class of convex loss functions. Our work also reveals an interesting connection between regularization and privacy.},
	author = {Chaudhuri, Kamalika and Monteleoni, Claire},
	doi = {10.12720/jait.6.3.88-95},
	file = {:home/bernd/Dropbox/hotstuff/iML/Privacy-preserving logistic regression.pdf:pdf},
	isbn = {9781605609492},
	issn = {17982340},
	journal = {Advances in Neural Information Processing Systems},
	pages = {289--296},
	title = {{Privacy-preserving logistic regression}},
	year = {2008}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
				THE OLD ONES...
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{DuchiJordan:2014:PrivacyAwareLearning,
   year = {2014},
   author = {Duchi, John C and Jordan, Michael I and Wainwright, Martin J},
   title = {Privacy aware learning},
   journal = {Journal of the ACM (JACM)},
   volume = {61},
   number = {6},
   pages = {38},
   abstract = {We study statistical risk minimization problems under a privacy model in which the data is kept confidential even from the learner. In this local privacy framework, we establish sharp upper and lower bounds on the convergence rates of statistical estimation procedures. As a consequence, we exhibit a precise tradeoff between the amount of privacy the data preserves and the utility, as measured by convergence rate, of any statistical estimator or learning procedure.},
   doi = {10.1145/2666468}
}

@article{Zhou:2008:SurveyAnonNetwork,
   year = {2008},
   author = {Zhou, Bin and Pei, Jian and Luk, WoShun},
   title = {A brief survey on anonymization techniques for privacy preserving publishing of social network data},
   journal = {ACM Sigkdd Explorations Newsletter},
   volume = {10},
   number = {2},
   pages = {12-22},
   abstract = {Nowadays, partly driven by many Web 2.0 applications, more and more social network data has been made publicly available and analyzed in one way or another. Privacy preserving publishing of social network data becomes a more and more important concern. In this paper, we present a brief yet systematic review of the existing anonymization techniques for privacy preserving publishing of social network data. We identify the new challenges in privacy preserving publishing of social network data comparing to the extensively studied relational case, and examine the possible problem formulation in three important dimensions: privacy, background knowledge, and data utility. We survey the existing anonymization methods for privacy preservation in two categories: clustering-based approaches and graph modification approaches.}
}


@article{Zheng:2013:reidentification,
   year = {2013},
   author = {Zheng, Wei-Shi and Gong, Shaogang and Xiang, Tao},
   title = {Reidentification by relative distance comparison},
   journal = {IEEE transactions on pattern analysis and machine intelligence},
   volume = {35},
   number = {3},
   pages = {653-668},
   abstract = {Matching people across nonoverlapping camera views at different locations and different times, known as person reidentification, is both a hard and important problem for associating behavior of people observed in a large distributed space over a prolonged period of time. Person reidentification is fundamentally challenging because of the large visual appearance changes caused by variations in view angle, lighting, background clutter, and occlusion. To address these challenges, most previous approaches aim to model and extract distinctive and reliable visual features. However, seeking an optimal and robust similarity measure that quantifies a wide range of features against realistic viewing conditions from a distance is still an open and unsolved problem for person reidentification. In this paper, we formulate person reidentification as a relative distance comparison (RDC) learning problem in order to learn the optimal similarity measure between a pair of person images. This approach avoids treating all features indiscriminately and does not assume the existence of some universally distinctive and reliable features. To that end, a novel relative distance comparison model is introduced. The model is formulated to maximize the likelihood of a pair of true matches having a relatively smaller distance than that of a wrong match pair in a soft discriminant manner. Moreover, in order to maintain the tractability of the model in large scale learning, we further develop an ensemble RDC model. Extensive experiments on three publicly available benchmarking datasets are carried out to demonstrate the clear superiority of the proposed RDC models over related popular person reidentification techniques. The results also show that the new RDC models are more robust against visual appearance changes and less susceptible to model overfitting compared to other related existing models.}
}

@article{NergizClifton:2010:Delta-Presence,
   year = {2010},
   author = {Nergiz, M. E. and Clifton, C.},
   title = {delta-Presence without Complete World Knowledge},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {22},
   number = {6},
   pages = {868-883},
   abstract = {Advances in information technology, and its use in research, are increasing both the need for anonymized data and the risks of poor anonymization. In [1], we presented a new privacy metric, delta-presence, that clearly links the quality of anonymization to the risk posed by inadequate anonymization. It was shown that existing anonymization techniques are inappropriate for situations where delta-presence is a good metric (specifically, where knowing an individual is in the database poses a privacy risk). This article addresses a practical problem with [1], extending to situations where the data anonymizer is not assumed to have complete world knowledge. The algorithms are evaluated in the context of a real-world scenario, demonstrating practical applicability of the approach.},
   keywords = {k-Anonymity, privacy, delta presence, medical databases},
   doi = {10.1109/tkde.2009.125}
}

@inproceedings{LiEtAl:2007:t-closeness,
   year = {2007},
   author = {Li, Ninghui and Li, Tiancheng and Venkatasubramanian, Suresh},
   title = {t-closeness: Privacy beyond k-anonymity and l-diversity},
   booktitle = {IEEE 23rd International Conference on Data Engineering, ICDE 2007},
   publisher = {IEEE},
   pages = {106-115},
   abstract = {The k-anonymity privacy requirement for publishing microdata requires that each equivalence class (i.e., a set of records that are indistinguishable from each other with respect to certain "identifying" attributes) contains at least k records. Recently, several authors have recognized that k-anonymity cannot prevent attribute disclosure. The notion of l-diversity has been proposed to address this; l-diversity requires that each equivalence class has at least l well-represented values for each sensitive attribute. In this paper we show that l-diversity has a number of limitations. In particular, it is neither necessary nor sufficient to prevent attribute disclosure. We propose a novel privacy notion called t-closeness, which requires that the distribution of a sensitive attribute in any equivalence class is close to the distribution of the attribute in the overall table (i.e., the distance between the two distributions should be no more than a threshold t). We choose to use the earth mover distance measure for our t-closeness requirement. We discuss the rationale for t-closeness and illustrate its advantages through examples and experiments.},
   doi = {10.1109/ICDE.2007.367856}
}

@article{MachanavajjhalaEtAl:2007:l-Diversity,
   year = {2007},
   author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
   title = {l-diversity: Privacy beyond k-anonymity},
   journal = {ACM Transactions on Knowledge Discovery from Data (TKDD)},
   volume = {1},
   number = {1},
   pages = {1-52},
   abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called k-anonymity has gained popularity. In a k-anonymized dataset, each record is indistinguishable from at least k − 1 other records with respect to certain identifying attributes. In this article, we show using two simple attacks that a k-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that k-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called ℓ-diversity that can defend against such attacks. In addition to building a formal foundation for ℓ-diversity, we show in an experimental evaluation that ℓ-diversity is practical and can be implemented efficiently.},
   doi = {10.1145/1217299.1217302}
}

@article{Sweeney:2002:k-Anonymity,
   year = {2002},
   author = {Sweeney, Latanya},
   title = {Achieving k-anonymity privacy protection using generalization and suppression},
   journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
   volume = {10},
   number = {5},
   pages = {571-588},
   abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, μ-Argus and k-Similar provide guarantees of privacy protection.},
   keywords = {Data anonymity; data privacy; re-identification; data fusion; privacy},
   doi = {10.1142/S0218488502001648 },
   url = {http://www.worldscientific.com/doi/abs/10.1142/S0218488502001648}
}

@inproceedings{Aggarwal:2005:kAnonymity,
   year = {2005},
   author = {Aggarwal, Charu C},
   title = {On k-anonymity and the curse of dimensionality},
   booktitle = {Proceedings of the 31st international conference on Very large data bases VLDB},
   pages = {901-909},
   abstract = {In recent years, the wide availability of personal data has made the problem of privacy preserving data mining an important one. A number of methods have recently been proposed for privacy preserving data mining of multidimensional data records. One of the methods for privacy preserving data mining is that of anonymization, in which a record is released only if it is indistinguishable from k other entities in the data. We note that methods such as k-anonymity are highly dependent upon spatial locality in order to effectively implement the technique in a statistically robust way. In high dimensional space the data becomes sparse, and the concept of spatial locality is no longer easy to define from an application point of view. In this paper, we view the k-anonymization problem from the perspective of inference attacks over all possible combinations of attributes. We show that when the data contains a large number of attributes which may be considered quasi-identifiers, it becomes difficult to anonymize the data without an unacceptably high amount of information loss. This is because an exponential number of combinations of dimensions can be used to make precise inference attacks, even when individual attributes are partially specified within a range. We provide an analysis of the effect of dimensionality on k-anonymity methods. We conclude that when a data set contains a large number of attributes which are open to inference attacks, we are faced with a choice of either completely suppressing most of the data or losing the desired level of anonymity. Thus, this paper shows that the curse of high dimensionality also applies to the problem of privacy preserving data mining.}
}

@article{Samarati:2001:kAnonymity,
   year = {2001},
   author = {Samarati, Pierangela},
   title = {Protecting respondents identities in microdata release},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {13},
   number = {6},
   pages = {1010-1027},
   abstract = {Today’s globally networked society places great demand on the dissemination and sharing of information. While in the past released information was mostly in tabular and statistical form, many situations call today for the release of specific data (microdata). In order to protect the anonymity of the entities (called respondents) to which information refers, data holders often remove or encrypt explicit identifiers such as names, addresses, and phone numbers. De-identifying data, however, provides no guarantee of anonymity. Released information often contains other data, such as race, birth date, sex, and ZIP code, that can be linked to publicly available information to re-identify respondents and inferring information that was not intended for disclosure. In this paper we address the problem of releasing microdata while safeguarding the anonymity of the respondents to which the data refer. The approach is based on the definition of k-anonymity . A table provides k-anonymity if attempts to link explicitly identifying information to its content map the information to at least k entities. We illustrate how k-anonymity can be provided without compromising the integrity (or truthfulness) of the information released by using generalization and suppression techniques. We introduce the concept of minimal generalization that captures the property of the release process not to distort the data more than needed to achieve k-anonymity, and present an algorithm for the computation of such a generalization. We also discuss possible preference policies to choose among different minimal generalizations. },
   keywords = {Privacy, Data Protection},
   doi = {10.1109/69.971193},
   url = {http://spdp.di.unimi.it/papers/tkde_k-anonymity.pdf}
}

@incollection{HolzingerMalleGiuliani2014GraphExtraction,
   year = {2014},
   author = {Holzinger, Andreas and Malle, Bernd and Giuliani, Nicola},
   title = {On Graph Extraction from Image Data},
   booktitle = {Brain Informatics and Health, BIH 2014, Lecture Notes in Artificial Intelligence, LNAI 8609},
   editor = {Slezak, Dominik and Peters, James F. and Tan, Ah-Hwee and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {552-563},
   abstract = {Hot topics in knowledge discovery and interactive data mining from natural images include the application of topological methods and machine learning algorithms. For any such approach one needs at first a relevant and robust digital content representation from the image data. However, traditional pixel-based image analysis techniques do not effectively extract, hence represent the content. A very promising approach is to extract graphs from images, which is not an easy task. In this paper we present a novel approach for knowledge discovery by extracting graph structures from natural image data. For this purpose, we created a framework built upon modern Web technologies, utilizing HTML canvas and pure Javascript inside a Web-browser, which is a very promising engineering approach. Following a short description of some popular image classification and segmentation methodologies, we outline a specific data processing pipeline suitable for carrying out future scientific research. A demonstration of our implementation, compared to the results of a traditional watershed transformation performed in Matlab showed very promising results in both quality and runtime, despite some remaining challenges. Finally, we provide a short discussion of a few open problems and outline some of our future research routes.},
   keywords = {data preprocessing, image segmentation, image content analytics, knowledge discovery, data mining},
   doi = {10.1007/978-3-319-09891-3_50},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=868952&pCurrPk=80830}
}

@incollection{HolzingerEtAl2014OnPCD,
   year = {2014},
   author = {Holzinger, Andreas and Malle, Bernd and Bloice, Marcus and Wiltgen, Marco and Ferri, Massimo and Stanganelli, Ignazio and Hofmann-Wellenhof, Rainer},
   title = {On the Generation of Point Cloud Data Sets: Step One in the Knowledge Discovery Process},
   booktitle = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics, Lecture Notes in Computer Science, LNCS 8401},
   editor = {Holzinger, Andreas and Jurisica, Igor},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   volume = {8401},
   pages = {57-80},
   abstract = {Computational geometry and topology are areas which have much potential for the analysis of arbitrarily high-dimensional data sets. In order to apply geometric or topological methods one must first generate a representative point cloud data set from the original data source, or at least a metric or distance function, which defines a distance between the elements of a given data set. Consequently, the first question is: How to get point cloud data sets? Or more precise: What is the optimal way of generating such data sets? The solution to these questions is not trivial. If a natural image is taken as an example, we are concerned more with the content, with the shape of the relevant data represented by this image than its mere matrix of pixels. Once a point cloud has been generated from a data source, it can be used as input for the application of graph theory and computational topology. In this paper we first describe the case for natural point clouds, i.e. where the data already are represented by points; we then provide some fundamentals of medical images, particularly dermoscopy, confocal laser scanning microscopy, and total-body photography; we describe the use of graph theoretic concepts for image analysis, give some medical background on skin cancer and concentrate on the challenges when dealing with lesion images. We discuss some relevant algorithms, including the watershed algorithm, region splitting (graph cuts), region merging (minimum spanning tree) and finally describe some open problems and future challenges [Graph-based Data Mining].},
   keywords = {data preprocessing, point cloud data sets, graphs, skin cancer, watershed algorithm, region splitting, graph cuts, region merging, mathematical morphology},
   doi = {10.1007/978-3-662-43968-5_4},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974579&pCurrPk=83005}
}

@incollection{PreussEtAl2014TerrainCoverage,
   year = {2014},
   author = {Preuss, Michael and Dehmer, Matthias and Pickl, Stefan and Holzinger, Andreas},
   title = {On Terrain Coverage Optimization by Using a Network Approach for universal Graph-based Data Mining and Knowledge Discovery},
   booktitle = {BIH 2014 Lecture Notes in Artificial Intelligence LNAI 8609 },
   editor = {Slezak, Dominik and Tan, Ah-Hwee and Peters, James F.  and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {564-573},
   abstract = {This conceptual paper discusses a graph-based approach for on-line terrain coverage, which has many important research aspects and a wide range of application possibilities, e.g in multi-agents. Such approaches can be used in different application domains, e.g. in medical image analysis. In this paper we discuss how the graphs are being generated and analyzed. In particular, the analysis is important for improving the estimation of the parameter set for the used heuristic in the field of route planning. Moreover, we describe some methods from quantitative graph theory and outline a few potential research routes.},
   keywords = {graph algorithms, multi agents, quantitative graph theory},
   doi = {10.1007/978-3-319-09891-3_51},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974170&pCurrPk=82989}
}

@incollection{Holzinger2014ExtravaganzaTutorial,
   year = {2014},
   author = {Holzinger, Andreas},
   title = {Extravaganza Tutorial on Hot Ideas for Interactive Knowledge Discovery and Data Mining in Biomedical Informatics},
   booktitle = {Brain Informatics and Health, BIH 2014, Lecture Notes in Artificial Intelligence, LNAI 8609},
   editor = {Slezak, Dominik and Tan, Ah-Hwee and Peters, James F and Schwabe, Lars},
   publisher = {Springer},
   address = {Heidelberg, Berlin},
   pages = {502-515},
   abstract = {Hot topics in knowledge discovery and interactive data mining from natural images include the application of topological methods and machine learning algorithms. For any such approach one needs at first a relevant and robust digital content representation from the image data. However, traditional pixel-based image analysis techniques do not effectively extract, hence represent the content. A very promising approach is to extract graphs from images, which is not an easy task. In this paper we present a novel approach for knowledge discovery by extracting graph structures from natural image data. For this purpose, we created a framework built upon modern Web technologies, utilizing HTML canvas and pure Javascript inside a Web-browser, which is a very promising engineering approach. Following a short description of some popular image classification and segmentation methodologies, we outline a specific data processing pipeline suitable for carrying out future scientific research. A demonstration of our implementation, compared to the results of a traditional watershed transformation performed in Matlab showed very promising results in both quality and runtime, despite some remaining challenges. Finally, we provide a short discussion of a few open problems and outline some of our future research routes.},
   keywords = {Knowledge Discovery, Data Mining, HCI-KDD, Graph-based Text Mining, Topological Data Mining, Entropy-based Data Mining},
   doi = {10.1007/978-3-319-09891-3_46},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=868952&pCurrPk=80830}
}

@incollection{HolzingerOfnerDehmer2014GraphMining,
   year = {2014},
   author = {Holzinger, Andreas and Ofner, Bernhard and Dehmer, Matthias},
   title = {Multi-touch Graph-Based Interaction for Knowledge Discovery on Mobile Devices: State-of-the-Art and Future Challenges},
   booktitle = {Interactive Knowledge Discovery and Data Mining in Biomedical Informatics, Lecture Notes in Computer Science, LNCS 8401},
   editor = {Holzinger, Andreas and Jurisica, Igor},
   publisher = {Springer},
   address = {Berlin Heidelberg},
   pages = {241-254},
   abstract = {Graph-based knowledge representation is a hot topic for some years and still has a lot of research potential, particularly in the advancement in the application of graph-theory for creating benefits in the biomedical domain. Graphs are most powerful tools to map structures within a given data set and to recognize relationships between specific data objects. Many advantages of graph-based data structures can be found in the applicability of methods from network analysis, topology and data mining (e.g. small-world phenomenon, cluster analysis). In this paper we present the state-of-the-art in graph-based approaches for multi-touch interaction on mobile devices and we highlight some open problems to stimulate further research and future developments. This is particularly important in the medical domain, as a conceptual graph analysis may provide novel insights on hidden patterns in data, hence support interactive knowledge discovery.[Graph-based Data Mining]},
   keywords = {Graph Based Interaction, Graph-based Data Mining, Interactive Node-Link Graph Visualization},
   doi = {10.1007/978-3-662-43968-5_14},
   url = {https://online.tugraz.at/tug_online/voe_main2.getVollText?pDocumentNr=974629&pCurrPk=83008}
}

@article{sweeney2002k,
	title={k-anonymity: A model for protecting privacy},
	author={Sweeney, Latanya},
	journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	volume={10},
	number={05},
	pages={557--570},
	year={2002},
	publisher={World Scientific}
}

@incollection{ciriani2007kappa,
	title={$\kappa$-anonymity},
	author={Ciriani, Valentina and di Vimercati, S De Capitani and Foresti, Sara and Samarati, Pierangela},
	booktitle={Secure data management in decentralized systems},
	pages={323--353},
	year={2007},
	publisher={Springer}
}

@article{aggarwal2005approximation,
	title={Approximation algorithms for k-anonymity},
	author={Aggarwal, Gagan and Feder, Tomas and Kenthapadi, Krishnaram and Motwani, Rajeev and Panigrahy, Rina and Thomas, Dilys and Zhu, An},
	journal={Journal of Privacy Technology (JOPT)},
	year={2005}
}

@article{chester2011k,
	title={k-Anonymization of Social Networks by Vertex Addition.},
	author={Chester, Sean and Kapron, Bruce and Ramesh, Ganesh and Srivastava, Gautam and Thomo, Alex and Venkatesh, S},
	journal={ADBIS (2)},
	volume={789},
	pages={107--116},
	year={2011}
}

@inproceedings{kapron2011social,
	title={Social network anonymization via edge addition},
	author={Kapron, Bruce and Srivastava, Gautam and Venkatesh, S},
	booktitle={Advances in Social Networks Analysis and Mining (ASONAM), 2011 International Conference on},
	pages={155--162},
	year={2011},
	organization={IEEE}
}

@incollection{campan2009data,
	title={Data and structural k-anonymity in social networks},
	author={Campan, Alina and Truta, Traian Marius},
	booktitle={Privacy, Security, and Trust in KDD},
	pages={33--54},
	year={2009},
	publisher={Springer}
}

@inproceedings{dwork2008differential,
	title={Differential privacy: A survey of results},
	author={Dwork, Cynthia},
	booktitle={International Conference on Theory and Applications of Models of Computation},
	pages={1--19},
	year={2008},
	organization={Springer}
}
